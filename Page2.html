<!DOCTYPE html> 
<html>
  <div class="w3-bar" style="background-color: #333; color: black; padding: 10px; border: 2px solid black; border-radius: 5px;">
  <a href="index.html" class="w3-bar-item w3-button" style="color: darkcyan;">Back to Home</a>
  <a href="sample.html" class="w3-bar-item w3-button" style="color: lightblue;">Page 1</a>
  <a href="Page2.html" class="w3-bar-item w3-button" style="color: lightblue;">Page 2</a>
  <a href="page3.html" class="w3-bar-item w3-button" style="color: lightblue;">Page 3</a>
   <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
</div>
  <style>
     body{color: lightblue;
     background-color: black;
     }
     </style>
<p style="border: 1px solid black; border-radius: 5px; padding: 5px;">4th Generation: The invention of the microprocessors brought along the fourth generation of computers. The years 1971-1980 were dominated by fourth generation computers. C, C++ and Java were the programming languages utilized in this generation of computers. For instance, the STAR 1000, PDP 11, CRAY-1, CRAY-X-MP, and Apple II. This was when we started producing computers for home use.</p>
<p style="border: 1px solid black; border-radius: 5px; padding: 5px;">5th Generation: These computers have been utilized since 1980 and continue to be used now. This is the present and the future of the computer world. The defining aspect of this generation is artificial intelligence. The use of parallel processing and superconductors are making this a reality and provide a lot of scope for the future. Fifth-generation computers use ULSI (Ultra Large Scale Integration) technology. These are the most recent and sophisticated computers. C, C++, Java,.Net, and more programming languages are used. For instance, IBM, Pentium, Desktop, Laptop, Notebook, Ultrabook, and so on.</p>
  <p style="border: 1px solid black; border-radius: 5px; padding: 5px;">The naive understanding of computation had to be overcome before the true power of computing could be realized. The inventors who worked tirelessly to bring the computer into the world had to realize that what they were creating was more than just a number cruncher or a calculator. They had to address all of the difficulties associated with inventing such a machine, implementing the design, and actually building the thing. The history of the computer is the history of these difficulties being solved.</p>
  <p style="border: 1px solid black; border-radius: 5px; padding: 5px;">
  19th Century
  1801 – Joseph Marie Jacquard, a weaver and businessman from France, devised a loom that employed punched wooden cards to automatically weave cloth designs.
  1822 – Charles Babbage, a mathematician, invented the steam-powered calculating machine capable of calculating number tables. The “Difference Engine” idea failed owing to a lack of technology at the time.
    <br>
  1848 – The world’s first computer program was written by Ada Lovelace, an English mathematician. Lovelace also includes a step-by-step tutorial on how to compute Bernoulli numbers using Babbage’s machine.
    <br>
  1890 – Herman Hollerith, an inventor, creates the punch card technique used to calculate the 1880 U.S. census. He would go on to start the corporation that would become IBM.
    <br>
  Early 20th Century
  1930 – Differential Analyzer was the first large-scale automatic general-purpose mechanical analogue computer invented and built by Vannevar Bush.
    <br>
  1936 – Alan Turing had an idea for a universal machine, which he called the Turing machine, that could compute anything that could be computed.
    <br>
  1939 – Hewlett-Packard was discovered in a garage in Palo Alto, California by Bill Hewlett and David Packard.
    <br>
  1941 – Konrad Zuse, a German inventor and engineer, completed his Z3 machine, the world’s first digital computer. However, the machine was destroyed during a World War II bombing strike on Berlin.
    <br>
  1941 – J.V. Atanasoff and graduate student Clifford Berry devise a computer capable of solving 29 equations at the same time. The first time a computer can store data in its primary memory.
    <br>
  1945 – University of Pennsylvania academics John Mauchly and J. Presper Eckert create an Electronic Numerical Integrator and Calculator (ENIAC). It was Turing-complete and capable of solving “a vast class of numerical problems” by reprogramming, earning it the title of “Grandfather of computers.”
    <br>
  1946 – The UNIVAC I (Universal Automatic Computer) was the first general-purpose electronic digital computer designed in the United States for corporate applications.
    <br>
  1949 – The Electronic Delay Storage Automatic Calculator (EDSAC), developed by a team at the University of Cambridge, is the “first practical stored-program computer.”
    <br>
  1950 – The Standards Eastern Automatic Computer (SEAC) was built in Washington, DC, and it was the first stored-program computer completed in the United States.
    <br>
  Late 20th Century
  1953 – Grace Hopper, a computer scientist, creates the first computer language, which becomes known as COBOL, which stands for COmmon, Business-Oriented Language. It allowed a computer user to offer the computer instructions in English-like words rather than numbers.
    <br>
  1954 – John Backus and a team of IBM programmers created the FORTRAN programming language, an acronym for FORmula TRANslation. In addition, IBM developed the 650.
    <br>
  1958 – The integrated circuit, sometimes known as the computer chip, was created by Jack Kirby and Robert Noyce.
    <br>
</p>